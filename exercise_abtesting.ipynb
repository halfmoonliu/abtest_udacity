{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing the Udacity Website\n",
    "\n",
    "In these exercises, we'll be analyzing data on user behavior from an experiment run by Udacity, the online education company. More specifically, we'll be looking at a test Udacity ran to improve the onboarding process on their site.\n",
    "\n",
    "Udacity's test is an example of an \"A/B\" test, in which some portion of users visiting a website (or using an app) are randomly selected to see a new version of the site. An analyst can then compare the behavior of users who see a new website design to users seeing their normal website to estimate the effect of rolling out the proposed changes to all users. While this kind of experiment has it's own name in industry (A/B testing), to be clear it's just a randomized experiment, and so everything we've learned about potential outcomes and randomized experiments apply here. \n",
    "\n",
    "(Udacity has generously provides the data from this test under an Apache open-source license, and you can find their [original writeup here](https://www.kaggle.com/tammyrotem/ab-tests-with-python/notebook). If you're interested in learning more on A/B testing in particular, it seems only fair while we use their data to flag they have a full course on the subject [here](https://www.udacity.com/course/ab-testing--ud257).)\n",
    "\n",
    "## Udacity's Test\n",
    "\n",
    "The test [is described by Udacity as follows](https://www.kaggle.com/tammyrotem/ab-tests-with-python/notebook): \n",
    "\n",
    "At the time of this experiment, Udacity courses currently have two options on the course overview page: \"start free trial\", and \"access course materials\".\n",
    "\n",
    "**Current Conditions Before Change**\n",
    "\n",
    "- If the student clicks \"start free trial\", they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first.\n",
    "- If the student clicks \"access course materials\", they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback.\n",
    "\n",
    "**Description of Experimented Change**\n",
    "\n",
    "- In the experiment, Udacity tested a change where if the student clicked \"start free trial\", they were asked how much time they had available to devote to the course.\n",
    "- If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free.\n",
    "- At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead. This [screenshot](images/udacity_checkyoureready.png) shows what the experiment looks like.\n",
    "\n",
    "**Udacity's Hope is that...**:\n",
    "\n",
    "> this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough time -- without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Gradescope Autograding\n",
    "\n",
    "Please follow [all standard guidance](https://www.practicaldatascience.org/html/autograder_guidelines.html) for submitting this assignment to the Gradescope autograder, including storing your solutions in a dictionary called `results` and ensuring your notebook runs from the start to completion without any errors.\n",
    "\n",
    "For this assignment, please name your file `exercise_abtesting.ipynb` before uploading.\n",
    "\n",
    "You can check that you have answers for all questions in your `results` dictionary with this code:\n",
    "\n",
    "```python\n",
    "assert set(results.keys()) == {\n",
    "    \"ex4_avg_oec\",\n",
    "    \"ex5_avg_guardrail\",\n",
    "    \"ex7_ttest_pvalue\",\n",
    "    \"ex9_ttest_pvalue_clicks\",\n",
    "    \"ex10_num_obs\",\n",
    "    \"ex11_guard_ate\",\n",
    "    \"ex11_guard_pvalue\",\n",
    "    \"ex11_oec_ate\",\n",
    "    \"ex11_oec_pvalue\",\n",
    "    \"ex14_se_treatment\",\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "### Submission Limits\n",
    "\n",
    "Please remember that you are **only allowed FOUR submissions to the autograder.** Your last submission (if you submit 4 or fewer times), or your third submission (if you submit more than 4 times) will determine your grade Submissions that error out will **not** count against this total.\n",
    "\n",
    "That's one more than usual in case there are issues with exercise clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"mode.copy_on_write\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Begin by importing Udacity's data on user behavior [here.](https://github.com/nickeubank/MIDS_Data/tree/master/udacity_AB_testing) \n",
    "\n",
    "There are TWO datasets for this test â€” one for the control data (users who saw the original design), and one for treatment data (users who saw the experimental design). Udacity decided to show their test site to 1/2 of visitors, so there are roughly the same number of users appearing in each dataset (though this is not a requirement of AB tests).\n",
    "\n",
    "Please remember to load the data directly from github to assist the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_dataset = pd.read_csv(\n",
    "    \"https://github.com/nickeubank/MIDS_Data/raw/master/udacity_AB_testing/control_data.csv\"\n",
    ")\n",
    "\n",
    "experiment_dataset = pd.read_csv(\n",
    "    \"https://github.com/nickeubank/MIDS_Data/raw/master/udacity_AB_testing/experiment_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723</td>\n",
       "      <td>687</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102</td>\n",
       "      <td>779</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511</td>\n",
       "      <td>909</td>\n",
       "      <td>167.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871</td>\n",
       "      <td>836</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014</td>\n",
       "      <td>837</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thu, Oct 16</td>\n",
       "      <td>9670</td>\n",
       "      <td>823</td>\n",
       "      <td>138.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fri, Oct 17</td>\n",
       "      <td>9008</td>\n",
       "      <td>748</td>\n",
       "      <td>146.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sat, Oct 18</td>\n",
       "      <td>7434</td>\n",
       "      <td>632</td>\n",
       "      <td>110.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sun, Oct 19</td>\n",
       "      <td>8459</td>\n",
       "      <td>691</td>\n",
       "      <td>131.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mon, Oct 20</td>\n",
       "      <td>10667</td>\n",
       "      <td>861</td>\n",
       "      <td>165.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tue, Oct 21</td>\n",
       "      <td>10660</td>\n",
       "      <td>867</td>\n",
       "      <td>196.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wed, Oct 22</td>\n",
       "      <td>9947</td>\n",
       "      <td>838</td>\n",
       "      <td>162.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thu, Oct 23</td>\n",
       "      <td>8324</td>\n",
       "      <td>665</td>\n",
       "      <td>127.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fri, Oct 24</td>\n",
       "      <td>9434</td>\n",
       "      <td>673</td>\n",
       "      <td>220.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sat, Oct 25</td>\n",
       "      <td>8687</td>\n",
       "      <td>691</td>\n",
       "      <td>176.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sun, Oct 26</td>\n",
       "      <td>8896</td>\n",
       "      <td>708</td>\n",
       "      <td>161.0</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mon, Oct 27</td>\n",
       "      <td>9535</td>\n",
       "      <td>759</td>\n",
       "      <td>233.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tue, Oct 28</td>\n",
       "      <td>9363</td>\n",
       "      <td>736</td>\n",
       "      <td>154.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wed, Oct 29</td>\n",
       "      <td>9327</td>\n",
       "      <td>739</td>\n",
       "      <td>196.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Thu, Oct 30</td>\n",
       "      <td>9345</td>\n",
       "      <td>734</td>\n",
       "      <td>167.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fri, Oct 31</td>\n",
       "      <td>8890</td>\n",
       "      <td>706</td>\n",
       "      <td>174.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sat, Nov 1</td>\n",
       "      <td>8460</td>\n",
       "      <td>681</td>\n",
       "      <td>156.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sun, Nov 2</td>\n",
       "      <td>8836</td>\n",
       "      <td>693</td>\n",
       "      <td>206.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mon, Nov 3</td>\n",
       "      <td>9437</td>\n",
       "      <td>788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tue, Nov 4</td>\n",
       "      <td>9420</td>\n",
       "      <td>781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wed, Nov 5</td>\n",
       "      <td>9570</td>\n",
       "      <td>805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Thu, Nov 6</td>\n",
       "      <td>9921</td>\n",
       "      <td>830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fri, Nov 7</td>\n",
       "      <td>9424</td>\n",
       "      <td>781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sat, Nov 8</td>\n",
       "      <td>9010</td>\n",
       "      <td>756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sun, Nov 9</td>\n",
       "      <td>9656</td>\n",
       "      <td>825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mon, Nov 10</td>\n",
       "      <td>10419</td>\n",
       "      <td>874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Tue, Nov 11</td>\n",
       "      <td>9880</td>\n",
       "      <td>830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Wed, Nov 12</td>\n",
       "      <td>10134</td>\n",
       "      <td>801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Thu, Nov 13</td>\n",
       "      <td>9717</td>\n",
       "      <td>814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fri, Nov 14</td>\n",
       "      <td>9192</td>\n",
       "      <td>735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sat, Nov 15</td>\n",
       "      <td>8630</td>\n",
       "      <td>743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sun, Nov 16</td>\n",
       "      <td>8970</td>\n",
       "      <td>722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Pageviews  Clicks  Enrollments  Payments\n",
       "0   Sat, Oct 11       7723     687        134.0      70.0\n",
       "1   Sun, Oct 12       9102     779        147.0      70.0\n",
       "2   Mon, Oct 13      10511     909        167.0      95.0\n",
       "3   Tue, Oct 14       9871     836        156.0     105.0\n",
       "4   Wed, Oct 15      10014     837        163.0      64.0\n",
       "5   Thu, Oct 16       9670     823        138.0      82.0\n",
       "6   Fri, Oct 17       9008     748        146.0      76.0\n",
       "7   Sat, Oct 18       7434     632        110.0      70.0\n",
       "8   Sun, Oct 19       8459     691        131.0      60.0\n",
       "9   Mon, Oct 20      10667     861        165.0      97.0\n",
       "10  Tue, Oct 21      10660     867        196.0     105.0\n",
       "11  Wed, Oct 22       9947     838        162.0      92.0\n",
       "12  Thu, Oct 23       8324     665        127.0      56.0\n",
       "13  Fri, Oct 24       9434     673        220.0     122.0\n",
       "14  Sat, Oct 25       8687     691        176.0     128.0\n",
       "15  Sun, Oct 26       8896     708        161.0     104.0\n",
       "16  Mon, Oct 27       9535     759        233.0     124.0\n",
       "17  Tue, Oct 28       9363     736        154.0      91.0\n",
       "18  Wed, Oct 29       9327     739        196.0      86.0\n",
       "19  Thu, Oct 30       9345     734        167.0      75.0\n",
       "20  Fri, Oct 31       8890     706        174.0     101.0\n",
       "21   Sat, Nov 1       8460     681        156.0      93.0\n",
       "22   Sun, Nov 2       8836     693        206.0      67.0\n",
       "23   Mon, Nov 3       9437     788          NaN       NaN\n",
       "24   Tue, Nov 4       9420     781          NaN       NaN\n",
       "25   Wed, Nov 5       9570     805          NaN       NaN\n",
       "26   Thu, Nov 6       9921     830          NaN       NaN\n",
       "27   Fri, Nov 7       9424     781          NaN       NaN\n",
       "28   Sat, Nov 8       9010     756          NaN       NaN\n",
       "29   Sun, Nov 9       9656     825          NaN       NaN\n",
       "30  Mon, Nov 10      10419     874          NaN       NaN\n",
       "31  Tue, Nov 11       9880     830          NaN       NaN\n",
       "32  Wed, Nov 12      10134     801          NaN       NaN\n",
       "33  Thu, Nov 13       9717     814          NaN       NaN\n",
       "34  Fri, Nov 14       9192     735          NaN       NaN\n",
       "35  Sat, Nov 15       8630     743          NaN       NaN\n",
       "36  Sun, Nov 16       8970     722          NaN       NaN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Explore the data. Can you identify the unit of observation of the data (e.g. what is represented by each row)?\n",
    "\n",
    "(Note this is not the only way that A/B test data can be collected and/or reported â€” this is just what Udacity provided, presumably to help address privacy concerns.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The unit of observation in the dataset is the total number of user engagement perday."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick your measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "The easiest way to analyze this data is to stack it into a single dataset where each observation is a day-treatment-arm (so you should end up with two rows per day, one for those who are in the treated groups, and one for those who were in the control group). Note that currently nothing in the data identifies whether a given observation is a treatment group observation or a control group observation, so you'll want to make sure to add a \"treatment\" indicator variable.\n",
    "\n",
    "The variables in the data are:\n",
    "\n",
    "- Pageviews: number of unique users visiting homepage\n",
    "- Clicks: number of those users clicking \"Start Free Trial\"\n",
    "- Enrollments: Number of people enrolling in trial\n",
    "- Payments: Number of people who eventually pay for the service. Note the `payment` column reports payments for the users who first visited the site on the reported date, not payments occurring on the reported date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fri, Nov 14</td>\n",
       "      <td>9192</td>\n",
       "      <td>735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fri, Nov 14</td>\n",
       "      <td>9304</td>\n",
       "      <td>770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fri, Nov 7</td>\n",
       "      <td>9424</td>\n",
       "      <td>781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fri, Nov 7</td>\n",
       "      <td>9272</td>\n",
       "      <td>767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fri, Oct 17</td>\n",
       "      <td>9088</td>\n",
       "      <td>780</td>\n",
       "      <td>127.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>9793</td>\n",
       "      <td>832</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wed, Oct 22</td>\n",
       "      <td>9947</td>\n",
       "      <td>838</td>\n",
       "      <td>162.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wed, Oct 22</td>\n",
       "      <td>9737</td>\n",
       "      <td>801</td>\n",
       "      <td>128.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wed, Oct 29</td>\n",
       "      <td>9262</td>\n",
       "      <td>727</td>\n",
       "      <td>201.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wed, Oct 29</td>\n",
       "      <td>9327</td>\n",
       "      <td>739</td>\n",
       "      <td>196.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Pageviews  Clicks  Enrollments  Payments      group\n",
       "34  Fri, Nov 14       9192     735          NaN       NaN    control\n",
       "34  Fri, Nov 14       9304     770          NaN       NaN  treatment\n",
       "27   Fri, Nov 7       9424     781          NaN       NaN    control\n",
       "27   Fri, Nov 7       9272     767          NaN       NaN  treatment\n",
       "6   Fri, Oct 17       9088     780        127.0      44.0  treatment\n",
       "..          ...        ...     ...          ...       ...        ...\n",
       "4   Wed, Oct 15       9793     832        140.0      94.0  treatment\n",
       "11  Wed, Oct 22       9947     838        162.0      92.0    control\n",
       "11  Wed, Oct 22       9737     801        128.0      70.0  treatment\n",
       "18  Wed, Oct 29       9262     727        201.0      96.0  treatment\n",
       "18  Wed, Oct 29       9327     739        196.0      86.0    control\n",
       "\n",
       "[74 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_dataset[\"group\"] = \"control\"\n",
    "experiment_dataset[\"group\"] = \"treatment\"\n",
    "\n",
    "Dataset = pd.concat([control_dataset, experiment_dataset])\n",
    "Dataset = Dataset.sort_values(by=[\"Date\"])\n",
    "Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Given Udacity's goals, what outcome are they hoping will be impacted by their manipulation?\n",
    "\n",
    "Or, to ask the same question in the language of the Potential Outcomes Framework, what is their $Y$?\n",
    "\n",
    "Or to ask the same question in the language of Kohavi, Tang and Xu, what is their *Overall Evaluation Criterion (OEC)*?\n",
    "\n",
    "(I'm only asking one question, I'm just trying to phrase it using different terminologies we've encountered to help you see how they all fit together)\n",
    "\n",
    "When you feel like you have your answer, please compute it. Store the average value of the variable in `results` under the key `ex4_avg_oec`. **Please round your answer to 4 decimal places.**\n",
    "\n",
    "NOTE: You'll probably notice you have two choices to make when it comes to actually computing the OEC. \n",
    "\n",
    "- You could probably imagine either computing a ratio or a difference of two things â€” please calculate the difference.\n",
    "- You may also be unsure whether to normalize by `Clicks`. Normalizing by clicks will help account for variation that comes from day-to-day variation in users, so it's a good thing to do. With infinite data, you'd expect to get the same results without normalizing by `Clicks` (since on average the same share of users are in each arm of the experiment), but for finite data it's a good strategy. Note that this is only ok because users make the choice to click or not *before* they see different versions of the website (it is \"pre-treatment\").\n",
    "\n",
    "Just to make sure you're on track, your measure should have an average value of *about* 9%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The *Overall Evaluation Criterion (OEC)* is the **enrollment rate**, or **share of people clicking on** *start free trial* **who actually enrolled for the trial**, ***minus*** **payment rate**, the **share of people of clicked on** *start free trial* who **continue on the paied service after the trial**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "      <th>group</th>\n",
       "      <th>Enrollment Rate</th>\n",
       "      <th>PaymentAmongClicked</th>\n",
       "      <th>Enroll_Pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fri, Nov 14</td>\n",
       "      <td>9192</td>\n",
       "      <td>735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fri, Nov 14</td>\n",
       "      <td>9304</td>\n",
       "      <td>770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>treatment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fri, Nov 7</td>\n",
       "      <td>9424</td>\n",
       "      <td>781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fri, Nov 7</td>\n",
       "      <td>9272</td>\n",
       "      <td>767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>treatment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fri, Oct 17</td>\n",
       "      <td>9088</td>\n",
       "      <td>780</td>\n",
       "      <td>127.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0.162821</td>\n",
       "      <td>0.056410</td>\n",
       "      <td>0.106410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>9793</td>\n",
       "      <td>832</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0.168269</td>\n",
       "      <td>0.112981</td>\n",
       "      <td>0.055288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wed, Oct 22</td>\n",
       "      <td>9947</td>\n",
       "      <td>838</td>\n",
       "      <td>162.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>control</td>\n",
       "      <td>0.193317</td>\n",
       "      <td>0.109785</td>\n",
       "      <td>0.083532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wed, Oct 22</td>\n",
       "      <td>9737</td>\n",
       "      <td>801</td>\n",
       "      <td>128.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.087391</td>\n",
       "      <td>0.072409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wed, Oct 29</td>\n",
       "      <td>9262</td>\n",
       "      <td>727</td>\n",
       "      <td>201.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0.276479</td>\n",
       "      <td>0.132050</td>\n",
       "      <td>0.144429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wed, Oct 29</td>\n",
       "      <td>9327</td>\n",
       "      <td>739</td>\n",
       "      <td>196.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>control</td>\n",
       "      <td>0.265223</td>\n",
       "      <td>0.116373</td>\n",
       "      <td>0.148850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Pageviews  Clicks  Enrollments  Payments      group  \\\n",
       "34  Fri, Nov 14       9192     735          NaN       NaN    control   \n",
       "34  Fri, Nov 14       9304     770          NaN       NaN  treatment   \n",
       "27   Fri, Nov 7       9424     781          NaN       NaN    control   \n",
       "27   Fri, Nov 7       9272     767          NaN       NaN  treatment   \n",
       "6   Fri, Oct 17       9088     780        127.0      44.0  treatment   \n",
       "..          ...        ...     ...          ...       ...        ...   \n",
       "4   Wed, Oct 15       9793     832        140.0      94.0  treatment   \n",
       "11  Wed, Oct 22       9947     838        162.0      92.0    control   \n",
       "11  Wed, Oct 22       9737     801        128.0      70.0  treatment   \n",
       "18  Wed, Oct 29       9262     727        201.0      96.0  treatment   \n",
       "18  Wed, Oct 29       9327     739        196.0      86.0    control   \n",
       "\n",
       "    Enrollment Rate  PaymentAmongClicked  Enroll_Pay  \n",
       "34              NaN                  NaN         NaN  \n",
       "34              NaN                  NaN         NaN  \n",
       "27              NaN                  NaN         NaN  \n",
       "27              NaN                  NaN         NaN  \n",
       "6          0.162821             0.056410    0.106410  \n",
       "..              ...                  ...         ...  \n",
       "4          0.168269             0.112981    0.055288  \n",
       "11         0.193317             0.109785    0.083532  \n",
       "11         0.159800             0.087391    0.072409  \n",
       "18         0.276479             0.132050    0.144429  \n",
       "18         0.265223             0.116373    0.148850  \n",
       "\n",
       "[74 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset[\"Enrollment Rate\"] = Dataset[\"Enrollments\"] / Dataset[\"Clicks\"]\n",
    "\n",
    "# calculate payment rate among clicked\n",
    "Dataset[\"PaymentAmongClicked\"] = Dataset[\"Payments\"] / Dataset[\"Clicks\"]\n",
    "\n",
    "\n",
    "# calculate difference\n",
    "Dataset[\"Enroll_Pay\"] = Dataset[\"Enrollment Rate\"] - Dataset[\"PaymentAmongClicked\"]\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Enroll_group = Dataset.groupby([\"group\"], as_index=False)[\"Enroll_Pay\"].mean()\n",
    "avg_oec = Enroll_group[\"Enroll_Pay\"].mean()\n",
    "\n",
    "ex4_avg_oec = round(avg_oec, 4)\n",
    "results[\"ex4_avg_oec\"] = ex4_avg_oec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex4_avg_oec': 0.0941}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Given Udacity's goals, what outcome are they hoping will *not* be impacted by their manipulation? In other words, what do they want to measure to ensure their treatment doesn't have unintended negative consequences that might be really costly to their operation?\n",
    "\n",
    "Note that while this isn't how Kohavi, Tang, and Xu use the term \"guardrail metrics\" â€” they usually use the term to refer to things we measure to ensure the experiment is working the way it should â€” some people would also use the term \"guardrail metrics\" for something that could be impacted even if the experiment is working correctly, but which the organization wants to track to ensure they aren't impacted because they are deemed really important.\n",
    "\n",
    "Again, please normalize by `Clicks`. Store the average value of this guardrail metric as `ex5_avg_guardrail` and **round your answer to 4 decimal places.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The enrollment rate in the control group. This metric is crucial for Udacity because it represents the baseline performance of their platform and courses.If the treatment has unintended negative consequences that significantly reduce the enrollment rate in the control group, it could indicate potential issues with the manipulation or changes introduced by Udacity, which would be costly to their operation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11582100814334004"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset[\"PaymentAmongClicked\"] = Dataset[\"Payments\"] / Dataset[\"Clicks\"]\n",
    "\n",
    "guard_group = Dataset.groupby([\"group\"], as_index=False)[\"PaymentAmongClicked\"].mean()\n",
    "guard_group[\"PaymentAmongClicked\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex4_avg_oec': 0.0941, 'ex5_avg_guardrail': 0.1158}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex5_avg_guardrail = guard_group[\"PaymentAmongClicked\"].mean()\n",
    "results[\"ex5_avg_guardrail\"] = round(ex5_avg_guardrail, 4)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating The Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Whenever you are working with experimental data, the first thing you want to do is verify that users actually were randomly sorted into the two arms of the experiment. In this data, half of users were supposed to be shown the old version of the site and half were supposed to see the new version.\n",
    "\n",
    "`Pageviews` tells you how many unique users visited the welcome site we are experimenting on. `Pageviews` is what is sometimes called an \"invariant\" or \"guardrail\" variable, meaning that it shouldn't vary across treatment armsâ€”after all, people have to visit the site before they get a chance to see the treatment, so there's no way that being assigned to treatment or control should affect the number of pageviews assigned to each group.\n",
    "\n",
    "\"Invariant\" variables are also an example of what are known as a \"pre-treatment\" variable, because pageviews are determined before users are manipulated in any way. That makes it analogous to gender or age in experiments where you have demographic dataâ€”a person's age and gender are determined before they experience any manipulations, so the value of any pre-treatment attributes should be the same across the two arms of our experiment. This is what we've previously called \"checking for balance,\" If pre-treatment attributes aren't balanced, then we may worry our attempt to randomly assign people to different groups failed.  Kohavi, Tang and Xu call this a \"trust-based guardrail metric\" because it helps us determine if we should trust our data.\n",
    "\n",
    "To test the quality of the randomization, calculate the average number of pageviews for the treated group and for the control group. Do they look similar?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "      <th>group</th>\n",
       "      <th>Enrollment Rate</th>\n",
       "      <th>PaymentAmongClicked</th>\n",
       "      <th>Enroll_Pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fri, Nov 14</td>\n",
       "      <td>9192</td>\n",
       "      <td>735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fri, Nov 14</td>\n",
       "      <td>9304</td>\n",
       "      <td>770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>treatment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fri, Nov 7</td>\n",
       "      <td>9424</td>\n",
       "      <td>781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fri, Nov 7</td>\n",
       "      <td>9272</td>\n",
       "      <td>767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>treatment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fri, Oct 17</td>\n",
       "      <td>9088</td>\n",
       "      <td>780</td>\n",
       "      <td>127.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0.162821</td>\n",
       "      <td>0.056410</td>\n",
       "      <td>0.106410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>9793</td>\n",
       "      <td>832</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0.168269</td>\n",
       "      <td>0.112981</td>\n",
       "      <td>0.055288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wed, Oct 22</td>\n",
       "      <td>9947</td>\n",
       "      <td>838</td>\n",
       "      <td>162.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>control</td>\n",
       "      <td>0.193317</td>\n",
       "      <td>0.109785</td>\n",
       "      <td>0.083532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wed, Oct 22</td>\n",
       "      <td>9737</td>\n",
       "      <td>801</td>\n",
       "      <td>128.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.087391</td>\n",
       "      <td>0.072409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wed, Oct 29</td>\n",
       "      <td>9262</td>\n",
       "      <td>727</td>\n",
       "      <td>201.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>0.276479</td>\n",
       "      <td>0.132050</td>\n",
       "      <td>0.144429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wed, Oct 29</td>\n",
       "      <td>9327</td>\n",
       "      <td>739</td>\n",
       "      <td>196.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>control</td>\n",
       "      <td>0.265223</td>\n",
       "      <td>0.116373</td>\n",
       "      <td>0.148850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Pageviews  Clicks  Enrollments  Payments      group  \\\n",
       "34  Fri, Nov 14       9192     735          NaN       NaN    control   \n",
       "34  Fri, Nov 14       9304     770          NaN       NaN  treatment   \n",
       "27   Fri, Nov 7       9424     781          NaN       NaN    control   \n",
       "27   Fri, Nov 7       9272     767          NaN       NaN  treatment   \n",
       "6   Fri, Oct 17       9088     780        127.0      44.0  treatment   \n",
       "..          ...        ...     ...          ...       ...        ...   \n",
       "4   Wed, Oct 15       9793     832        140.0      94.0  treatment   \n",
       "11  Wed, Oct 22       9947     838        162.0      92.0    control   \n",
       "11  Wed, Oct 22       9737     801        128.0      70.0  treatment   \n",
       "18  Wed, Oct 29       9262     727        201.0      96.0  treatment   \n",
       "18  Wed, Oct 29       9327     739        196.0      86.0    control   \n",
       "\n",
       "    Enrollment Rate  PaymentAmongClicked  Enroll_Pay  \n",
       "34              NaN                  NaN         NaN  \n",
       "34              NaN                  NaN         NaN  \n",
       "27              NaN                  NaN         NaN  \n",
       "27              NaN                  NaN         NaN  \n",
       "6          0.162821             0.056410    0.106410  \n",
       "..              ...                  ...         ...  \n",
       "4          0.168269             0.112981    0.055288  \n",
       "11         0.193317             0.109785    0.083532  \n",
       "11         0.159800             0.087391    0.072409  \n",
       "18         0.276479             0.132050    0.144429  \n",
       "18         0.265223             0.116373    0.148850  \n",
       "\n",
       "[74 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The control group pageview average is 9339.0\n",
      "The treatment group pageview average is 9315.135135135135\n",
      "The pageview for control group and treatment group is similar with the average of control group being higher than that of the treatment gorup.\n"
     ]
    }
   ],
   "source": [
    "control_average_pageviews = Dataset[Dataset[\"group\"] == \"control\"][\"Pageviews\"].mean()\n",
    "treatment_average_pageviews = Dataset[Dataset[\"group\"] == \"treatment\"][\n",
    "    \"Pageviews\"\n",
    "].mean()\n",
    "\n",
    "print(f\"The control group pageview average is {control_average_pageviews}\")\n",
    "print(f\"The treatment group pageview average is {treatment_average_pageviews}\")\n",
    "print(\n",
    "    \"The pageview for control group and treatment group is similar with the average of control group being higher than that of the treatment gorup.\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "\"Similar\" is a tricky concept -- obviously, we expect *some* differences across groups since users were *randomly* divided across treatment arms. The question is whether the differences between groups are larger than we'd expect to emerge given our random assignment process. To evaluate this, let's use a `ttest` to test the statistical significance of the differences we see. \n",
    "\n",
    "**Note**: Remember that scipy functions don't accept `pandas` objects, so you use a scipy function, you have to pass the numpy vectors underlying your data with the `.values` operator (e.g. `df.my_column.values`). \n",
    "\n",
    "Does the difference in `pageviews` look statistically significant?\n",
    "\n",
    "Store the resulting p-value in `ex7_ttest_pvalue` **rounded to four decimal places.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "pageviews_control = Dataset[Dataset[\"group\"] == \"control\"][\"Pageviews\"].values\n",
    "pageviews_treatment = Dataset[Dataset[\"group\"] == \"treatment\"][\"Pageviews\"].values\n",
    "\n",
    "t_statistic, p_value = ttest_ind(pageviews_treatment, pageviews_control)\n",
    "\n",
    "ex7_ttest_pvalue = round(p_value, 4)\n",
    "results[\"ex7_ttest_pvalue\"] = ex7_ttest_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A p_value of 0.8877 means we fail to reject the null hypothesis that there is no difference between the means in the control group and treatment group. \n",
    "From the data observed, we cannot conclude there is a difference between-group  of the pageviews."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "`Pageviews` is not the only \"pre-treatment\" variable in this data we can use to evaluate balance/use as a guardrail metric. What other measure is pre-treatment? Review the description of the experiment if you're not sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use clicks as a guardrail pre-treatment variable as the control group of clicks should be similar as that of the treatment group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The control group pageview average is 766.972972972973\n",
      "The treatment group pageview average is 765.5405405405405\n",
      "The clicks for control group and treatment group is similar with the average of control group being slightly higher than that of the treatment gorup.\n"
     ]
    }
   ],
   "source": [
    "control_average_clicks = Dataset[Dataset[\"group\"] == \"control\"][\"Clicks\"].mean()\n",
    "treatment_average_clicks = Dataset[Dataset[\"group\"] == \"treatment\"][\"Clicks\"].mean()\n",
    "\n",
    "\n",
    "print(f\"The control group pageview average is {control_average_clicks}\")\n",
    "print(f\"The treatment group pageview average is {treatment_average_clicks}\")\n",
    "print(\n",
    "    \"The clicks for control group and treatment group is similar with the average of control group being slightly higher than that of the treatment gorup.\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "Check if the other pre-treatment variable is also balanced. Store the p-value of your test of difference in `results` under the key `\"ex9_ttest_pvalue_clicks\"` **rounded to four decimal places.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex4_avg_oec': 0.0941,\n",
       " 'ex5_avg_guardrail': 0.1158,\n",
       " 'ex7_ttest_pvalue': 0.8877,\n",
       " 'ex9_ttest_pvalue_clicks': 0.9264}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks_control = Dataset[Dataset[\"group\"] == \"control\"][\"Clicks\"].values\n",
    "clicks_treatment = Dataset[Dataset[\"group\"] == \"treatment\"][\"Clicks\"].values\n",
    "\n",
    "t_statistic, p_value = ttest_ind(clicks_treatment, clicks_control)\n",
    "\n",
    "ex9_ttest_pvalue_clicks = round(p_value, 4)\n",
    "results[\"ex9_ttest_pvalue_clicks\"] = ex9_ttest_pvalue_clicks\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A p_value of 0.9264 means we fail to reject the null hypothesis that there is no difference between the means in the control group and treatment group. \n",
    "Therefore we cannot conclude that there no difference in the mean number of clicks between the treatment and control groups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Effect of Experiment\n",
    "\n",
    "### Exercise 10\n",
    "\n",
    "Now that we've validated our randomization, our next task is to estimate our treatment effect. First, though, there's an issue with your data you've been able to largely ignore until now, but which you should get a grip on before estimating your treatment effect â€” can you tell what it is and what you should do about it?\n",
    "\n",
    "Store the number of observations in your data *after* you've addressed this in `ex10_num_obs` (this is mostly meant as a way to sanity check your answer with autograder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_without_nas = Dataset.dropna()\n",
    "ex10_num_obs = dataset_without_nas.shape[0]\n",
    "results[\"ex10_num_obs\"] = ex10_num_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex4_avg_oec': 0.0941,\n",
       " 'ex5_avg_guardrail': 0.1158,\n",
       " 'ex7_ttest_pvalue': 0.8877,\n",
       " 'ex9_ttest_pvalue_clicks': 0.9264,\n",
       " 'ex10_num_obs': 46}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 11\n",
    "\n",
    "Now that we've established we have good balance (meaning we think randomization was likely successful), we can evaluate the effects of the experiment. Test whether the OEC and the metric you *don't* want affected have different average values in the control group and treatment group. \n",
    "\n",
    "Because we've randomized, this is a consistent estimate of the Average Treatment Effect of Udacity's website change.\n",
    "\n",
    "Calculate the difference in means in your OEC and guardrail metrics using a simple t-test. Store the resulting effect estimates in `ex11_oec_ate` and `ex11_guard_ate` and p-values in `ex11_oec_pvalue` and `ex11_guard_pvalue`. **Please round all answers to 4 decimal places.** Report your ATE in *percentage points*, where `1` denotes 1 percentage point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>Enroll And Payment Rate Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>control</td>\n",
       "      <td>0.102082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>treatment</td>\n",
       "      <td>0.086194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       group  Enroll And Payment Rate Difference\n",
       "0    control                            0.102082\n",
       "1  treatment                            0.086194"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oec_group = dataset_without_nas.groupby([\"group\"], as_index=False)[\"Enroll_Pay\"].mean()\n",
    "\n",
    "oec_group.rename(\n",
    "    {\"Enroll_Pay\": \"Enroll And Payment Rate Difference\"}, axis=1, inplace=True\n",
    ")\n",
    "\n",
    "oec_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex4_avg_oec': 0.0941,\n",
       " 'ex5_avg_guardrail': 0.1158,\n",
       " 'ex7_ttest_pvalue': 0.8877,\n",
       " 'ex9_ttest_pvalue_clicks': 0.9264,\n",
       " 'ex10_num_obs': 46,\n",
       " 'ex11_oec_ate': 1.5888,\n",
       " 'ex11_oec_pvalue': 0.1319}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oec_control = dataset_without_nas[dataset_without_nas[\"group\"] == \"control\"][\n",
    "    \"Enroll_Pay\"\n",
    "].values\n",
    "oec_treatment = dataset_without_nas[dataset_without_nas[\"group\"] == \"treatment\"][\n",
    "    \"Enroll_Pay\"\n",
    "].values\n",
    "\n",
    "\n",
    "t_stats_11_oec, t_p_value_11_oec = ttest_ind(oec_treatment, oec_control)\n",
    "\n",
    "oec_ate = (\n",
    "    oec_group.loc[1][\"Enroll And Payment Rate Difference\"]\n",
    "    - oec_group.loc[0][\"Enroll And Payment Rate Difference\"]\n",
    ")\n",
    "\n",
    "results[\"ex11_oec_ate\"] = round(abs(oec_ate * 100), 4)\n",
    "results[\"ex11_oec_pvalue\"] = round(t_p_value_11_oec, 4)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The negative value indicates that, on average, enrollment rates in the treatment group were approximately 21.8355 percentage points lower than in the control group.\n",
    "This could also be implied as the new feature proposed in the treatment group meant that they were 21.8355 less likely to enroll in the courses as compared to the control group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> With a p-value of `0.1308` we fail to reject the null hypothesis that there is no difference in the means between the Enrollment rate in the Control and the Treatment group. So we do not have enough evidence to conclude there is no difference in the means in the OEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>PaymentAmongClicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>control</td>\n",
       "      <td>0.118269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>treatment</td>\n",
       "      <td>0.113373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       group  PaymentAmongClicked\n",
       "0    control             0.118269\n",
       "1  treatment             0.113373"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guard_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex4_avg_oec': 0.0941,\n",
       " 'ex5_avg_guardrail': 0.1158,\n",
       " 'ex7_ttest_pvalue': 0.8877,\n",
       " 'ex9_ttest_pvalue_clicks': 0.9264,\n",
       " 'ex10_num_obs': 46,\n",
       " 'ex11_oec_ate': 1.5888,\n",
       " 'ex11_oec_pvalue': 0.1319,\n",
       " 'ex11_guard_ate': 0.4897,\n",
       " 'ex11_guard_pvalue': 0.5928}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guard_control = dataset_without_nas[dataset_without_nas[\"group\"] == \"control\"][\n",
    "    \"PaymentAmongClicked\"\n",
    "].values\n",
    "guard_treatment = dataset_without_nas[dataset_without_nas[\"group\"] == \"treatment\"][\n",
    "    \"PaymentAmongClicked\"\n",
    "].values\n",
    "\n",
    "\n",
    "t_stats_11_guard, t_p_value_11_guard = ttest_ind(guard_treatment, guard_control)\n",
    "\n",
    "guard_ate = (\n",
    "    guard_group.loc[1][\"PaymentAmongClicked\"]\n",
    "    - guard_group.loc[0][\"PaymentAmongClicked\"]\n",
    ") * 100\n",
    "\n",
    "results[\"ex11_guard_ate\"] = round(abs(guard_ate), 4)\n",
    "results[\"ex11_guard_pvalue\"] = round(t_p_value_11_guard, 4)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> With a p-value of `0.5928` we fail to reject the null hypothesis that there is no difference in the means between the guard rail metrics in the Control and the Treatment group. So we do not have enough evidence to conclude there is no difference in the means in the OEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12\n",
    "\n",
    "Do you feel that Udacity achieved their goal? Did their intervention cause them any problems? If they asked you \"What would happen if we rolled this out to everyone?\" what would you say?\n",
    "\n",
    "As you answer this question, a small additional question: up until this point you've (presumably) been reporting the default p-values from the tools you are using. These, as you may recall from stats 101, are two-tailed p-values. Do those seem appropriate for your OEC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Based on the result of t-test on** the OEC, or **daily enrollment rate among those clicked** on *start free trial*, we **cannot conclude that there is a treatment effect**. **Because we are interested in whether the treatment would decrease OEC, a one-tail t-test would be more appropriate**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13\n",
    "\n",
    "One of the magic things about experiments is that all you have to do is compare averages to get an average treatment effect. However, you *can* do other things to try and increase the statistical power of your experiments, like add controls in a linear regression model. \n",
    "\n",
    "As you likely know, a bivariate regression is exactly equivalent to a t-test, so let's start by re-estimating the effect of treatment on your OEC using a linear regression. Can you replicate the results from your t-test? They shouldn't just be closeâ€”they should be numerically equivalent (i.e. exactly the same to the limits of floating point number precision). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_without_nas.rename(columns={\"Enrollment Rate\": \"EnrollmentRate\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Enroll_Pay</td>    <th>  R-squared:         </th> <td>   0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 19 Mar 2024</td> <th>  Prob (F-statistic):</th>  <td> 0.132</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:48:25</td>     <th>  Log-Likelihood:    </th> <td>  89.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    46</td>      <th>  AIC:               </th> <td>  -175.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>  -172.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>    0.1021</td> <td>    0.007</td> <td>   13.948</td> <td> 0.000</td> <td>    0.087</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group[T.treatment]</th> <td>   -0.0159</td> <td>    0.010</td> <td>   -1.535</td> <td> 0.132</td> <td>   -0.037</td> <td>    0.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.160</td> <th>  Durbin-Watson:     </th> <td>   1.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  15.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.227</td> <th>  Prob(JB):          </th> <td>0.000499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.383</td> <th>  Cond. No.          </th> <td>    2.62</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}     &   Enroll\\_Pay    & \\textbf{  R-squared:         } &     0.051   \\\\\n",
       "\\textbf{Model:}             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.029   \\\\\n",
       "\\textbf{Method:}            &  Least Squares   & \\textbf{  F-statistic:       } &     2.356   \\\\\n",
       "\\textbf{Date:}              & Tue, 19 Mar 2024 & \\textbf{  Prob (F-statistic):} &    0.132    \\\\\n",
       "\\textbf{Time:}              &     00:48:25     & \\textbf{  Log-Likelihood:    } &    89.832   \\\\\n",
       "\\textbf{No. Observations:}  &          46      & \\textbf{  AIC:               } &    -175.7   \\\\\n",
       "\\textbf{Df Residuals:}      &          44      & \\textbf{  BIC:               } &    -172.0   \\\\\n",
       "\\textbf{Df Model:}          &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}          &       0.1021  &        0.007     &    13.948  &         0.000        &        0.087    &        0.117     \\\\\n",
       "\\textbf{group[T.treatment]} &      -0.0159  &        0.010     &    -1.535  &         0.132        &       -0.037    &        0.005     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 14.160 & \\textbf{  Durbin-Watson:     } &    1.481  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   15.205  \\\\\n",
       "\\textbf{Skew:}          &  1.227 & \\textbf{  Prob(JB):          } & 0.000499  \\\\\n",
       "\\textbf{Kurtosis:}      &  4.383 & \\textbf{  Cond. No.          } &     2.62  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Enroll_Pay   R-squared:                       0.051\n",
       "Model:                            OLS   Adj. R-squared:                  0.029\n",
       "Method:                 Least Squares   F-statistic:                     2.356\n",
       "Date:                Tue, 19 Mar 2024   Prob (F-statistic):              0.132\n",
       "Time:                        00:48:25   Log-Likelihood:                 89.832\n",
       "No. Observations:                  46   AIC:                            -175.7\n",
       "Df Residuals:                      44   BIC:                            -172.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept              0.1021      0.007     13.948      0.000       0.087       0.117\n",
       "group[T.treatment]    -0.0159      0.010     -1.535      0.132      -0.037       0.005\n",
       "==============================================================================\n",
       "Omnibus:                       14.160   Durbin-Watson:                   1.481\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               15.205\n",
       "Skew:                           1.227   Prob(JB):                     0.000499\n",
       "Kurtosis:                       4.383   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# fit regression\n",
    "model = ols(formula=\"Enroll_Pay ~ group\", data=dataset_without_nas).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the p-values obtained with the models\n",
    "assert round(model.pvalues[1], 4) == results[\"ex11_oec_pvalue\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14\n",
    "\n",
    "Now add indicator variables for the date of each observation. Do the standard errors on your `treatment` variable change? If so, in what direction?\n",
    "\n",
    "Store your new standard error in `ex14_se_treatment`. Round your answer to 4 decimal places."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have found that your standard errors decreased by about 30\\%â€”this is why, although just comparing means *works*, if you have additional variables adding them to your analysis can be helpful (all the usual rules for model specification apply â€” for example, you still want to be careful about overfitting, which one could argue is maybe part of what's happening here). \n",
    "\n",
    "In many other cases, the effect of adding controls is likely to be larger â€” the date indicators we added to our data are perfectly balanced between treatment and control, so we aren't adding a lot of data to the model by adding them as variables. They're accounting for some day-to-day variation (presumably in the types of people coming to the site), but they aren't controlling for any residual baseline differences the way a control like \"gender\" or \"age\" might (since those kind of individual-level attributes will never be perfectly balanced across treatment and control). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Enroll_Pay</td>    <th>  R-squared:         </th> <td>   0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 19 Mar 2024</td> <th>  Prob (F-statistic):</th> <td>0.000978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:50:06</td>     <th>  Log-Likelihood:    </th> <td>  126.29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    46</td>      <th>  AIC:               </th> <td>  -204.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    22</td>      <th>  BIC:               </th> <td>  -160.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>    0.1079</td> <td>    0.016</td> <td>    6.651</td> <td> 0.000</td> <td>    0.074</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group[T.treatment]</th>     <td>   -0.0159</td> <td>    0.007</td> <td>   -2.398</td> <td> 0.025</td> <td>   -0.030</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Fri, Oct 24]</th> <td>    0.0445</td> <td>    0.022</td> <td>    1.983</td> <td> 0.060</td> <td>   -0.002</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Fri, Oct 31]</th> <td>   -0.0074</td> <td>    0.022</td> <td>   -0.331</td> <td> 0.744</td> <td>   -0.054</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Mon, Oct 13]</th> <td>   -0.0231</td> <td>    0.022</td> <td>   -1.026</td> <td> 0.316</td> <td>   -0.070</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Mon, Oct 20]</th> <td>   -0.0285</td> <td>    0.022</td> <td>   -1.270</td> <td> 0.217</td> <td>   -0.075</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Mon, Oct 27]</th> <td>    0.0328</td> <td>    0.022</td> <td>    1.458</td> <td> 0.159</td> <td>   -0.014</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Sat, Nov 1]</th>  <td>   -0.0235</td> <td>    0.022</td> <td>   -1.047</td> <td> 0.306</td> <td>   -0.070</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Sat, Oct 11]</th> <td>   -0.0017</td> <td>    0.022</td> <td>   -0.074</td> <td> 0.941</td> <td>   -0.048</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Sat, Oct 18]</th> <td>   -0.0438</td> <td>    0.022</td> <td>   -1.950</td> <td> 0.064</td> <td>   -0.090</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Sat, Oct 25]</th> <td>   -0.0309</td> <td>    0.022</td> <td>   -1.375</td> <td> 0.183</td> <td>   -0.077</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Sun, Nov 2]</th>  <td>    0.0549</td> <td>    0.022</td> <td>    2.441</td> <td> 0.023</td> <td>    0.008</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Sun, Oct 12]</th> <td>   -0.0347</td> <td>    0.022</td> <td>   -1.542</td> <td> 0.137</td> <td>   -0.081</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Sun, Oct 19]</th> <td>   -0.0178</td> <td>    0.022</td> <td>   -0.791</td> <td> 0.437</td> <td>   -0.064</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Sun, Oct 26]</th> <td>   -0.0222</td> <td>    0.022</td> <td>   -0.989</td> <td> 0.333</td> <td>   -0.069</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Thu, Oct 16]</th> <td>   -0.0228</td> <td>    0.022</td> <td>   -1.016</td> <td> 0.321</td> <td>   -0.069</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Thu, Oct 23]</th> <td>   -0.0046</td> <td>    0.022</td> <td>   -0.203</td> <td> 0.841</td> <td>   -0.051</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Thu, Oct 30]</th> <td>    0.0588</td> <td>    0.022</td> <td>    2.618</td> <td> 0.016</td> <td>    0.012</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Tue, Oct 14]</th> <td>   -0.0417</td> <td>    0.022</td> <td>   -1.855</td> <td> 0.077</td> <td>   -0.088</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Tue, Oct 21]</th> <td>   -0.0059</td> <td>    0.022</td> <td>   -0.260</td> <td> 0.797</td> <td>   -0.052</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Tue, Oct 28]</th> <td>   -0.0287</td> <td>    0.022</td> <td>   -1.276</td> <td> 0.215</td> <td>   -0.075</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Wed, Oct 15]</th> <td>   -0.0132</td> <td>    0.022</td> <td>   -0.588</td> <td> 0.562</td> <td>   -0.060</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Wed, Oct 22]</th> <td>   -0.0220</td> <td>    0.022</td> <td>   -0.980</td> <td> 0.338</td> <td>   -0.069</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Date)[T.Wed, Oct 29]</th> <td>    0.0466</td> <td>    0.022</td> <td>    2.076</td> <td> 0.050</td> <td> 4.77e-05</td> <td>    0.093</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.871</td> <th>  Durbin-Watson:     </th> <td>   2.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.144</td> <th>  Jarque-Bera (JB):  </th> <td>   3.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.000</td> <th>  Prob(JB):          </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.413</td> <th>  Cond. No.          </th> <td>    27.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}         &   Enroll\\_Pay    & \\textbf{  R-squared:         } &     0.806   \\\\\n",
       "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.602   \\\\\n",
       "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     3.962   \\\\\n",
       "\\textbf{Date:}                  & Tue, 19 Mar 2024 & \\textbf{  Prob (F-statistic):} &  0.000978   \\\\\n",
       "\\textbf{Time:}                  &     00:50:06     & \\textbf{  Log-Likelihood:    } &    126.29   \\\\\n",
       "\\textbf{No. Observations:}      &          46      & \\textbf{  AIC:               } &    -204.6   \\\\\n",
       "\\textbf{Df Residuals:}          &          22      & \\textbf{  BIC:               } &    -160.7   \\\\\n",
       "\\textbf{Df Model:}              &          23      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}              &       0.1079  &        0.016     &     6.651  &         0.000        &        0.074    &        0.142     \\\\\n",
       "\\textbf{group[T.treatment]}     &      -0.0159  &        0.007     &    -2.398  &         0.025        &       -0.030    &       -0.002     \\\\\n",
       "\\textbf{C(Date)[T.Fri, Oct 24]} &       0.0445  &        0.022     &     1.983  &         0.060        &       -0.002    &        0.091     \\\\\n",
       "\\textbf{C(Date)[T.Fri, Oct 31]} &      -0.0074  &        0.022     &    -0.331  &         0.744        &       -0.054    &        0.039     \\\\\n",
       "\\textbf{C(Date)[T.Mon, Oct 13]} &      -0.0231  &        0.022     &    -1.026  &         0.316        &       -0.070    &        0.024     \\\\\n",
       "\\textbf{C(Date)[T.Mon, Oct 20]} &      -0.0285  &        0.022     &    -1.270  &         0.217        &       -0.075    &        0.018     \\\\\n",
       "\\textbf{C(Date)[T.Mon, Oct 27]} &       0.0328  &        0.022     &     1.458  &         0.159        &       -0.014    &        0.079     \\\\\n",
       "\\textbf{C(Date)[T.Sat, Nov 1]}  &      -0.0235  &        0.022     &    -1.047  &         0.306        &       -0.070    &        0.023     \\\\\n",
       "\\textbf{C(Date)[T.Sat, Oct 11]} &      -0.0017  &        0.022     &    -0.074  &         0.941        &       -0.048    &        0.045     \\\\\n",
       "\\textbf{C(Date)[T.Sat, Oct 18]} &      -0.0438  &        0.022     &    -1.950  &         0.064        &       -0.090    &        0.003     \\\\\n",
       "\\textbf{C(Date)[T.Sat, Oct 25]} &      -0.0309  &        0.022     &    -1.375  &         0.183        &       -0.077    &        0.016     \\\\\n",
       "\\textbf{C(Date)[T.Sun, Nov 2]}  &       0.0549  &        0.022     &     2.441  &         0.023        &        0.008    &        0.101     \\\\\n",
       "\\textbf{C(Date)[T.Sun, Oct 12]} &      -0.0347  &        0.022     &    -1.542  &         0.137        &       -0.081    &        0.012     \\\\\n",
       "\\textbf{C(Date)[T.Sun, Oct 19]} &      -0.0178  &        0.022     &    -0.791  &         0.437        &       -0.064    &        0.029     \\\\\n",
       "\\textbf{C(Date)[T.Sun, Oct 26]} &      -0.0222  &        0.022     &    -0.989  &         0.333        &       -0.069    &        0.024     \\\\\n",
       "\\textbf{C(Date)[T.Thu, Oct 16]} &      -0.0228  &        0.022     &    -1.016  &         0.321        &       -0.069    &        0.024     \\\\\n",
       "\\textbf{C(Date)[T.Thu, Oct 23]} &      -0.0046  &        0.022     &    -0.203  &         0.841        &       -0.051    &        0.042     \\\\\n",
       "\\textbf{C(Date)[T.Thu, Oct 30]} &       0.0588  &        0.022     &     2.618  &         0.016        &        0.012    &        0.105     \\\\\n",
       "\\textbf{C(Date)[T.Tue, Oct 14]} &      -0.0417  &        0.022     &    -1.855  &         0.077        &       -0.088    &        0.005     \\\\\n",
       "\\textbf{C(Date)[T.Tue, Oct 21]} &      -0.0059  &        0.022     &    -0.260  &         0.797        &       -0.052    &        0.041     \\\\\n",
       "\\textbf{C(Date)[T.Tue, Oct 28]} &      -0.0287  &        0.022     &    -1.276  &         0.215        &       -0.075    &        0.018     \\\\\n",
       "\\textbf{C(Date)[T.Wed, Oct 15]} &      -0.0132  &        0.022     &    -0.588  &         0.562        &       -0.060    &        0.033     \\\\\n",
       "\\textbf{C(Date)[T.Wed, Oct 22]} &      -0.0220  &        0.022     &    -0.980  &         0.338        &       -0.069    &        0.025     \\\\\n",
       "\\textbf{C(Date)[T.Wed, Oct 29]} &       0.0466  &        0.022     &     2.076  &         0.050        &     4.77e-05    &        0.093     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.871 & \\textbf{  Durbin-Watson:     } &    2.907  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.144 & \\textbf{  Jarque-Bera (JB):  } &    3.826  \\\\\n",
       "\\textbf{Skew:}          &  0.000 & \\textbf{  Prob(JB):          } &    0.148  \\\\\n",
       "\\textbf{Kurtosis:}      &  4.413 & \\textbf{  Cond. No.          } &     27.3  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Enroll_Pay   R-squared:                       0.806\n",
       "Model:                            OLS   Adj. R-squared:                  0.602\n",
       "Method:                 Least Squares   F-statistic:                     3.962\n",
       "Date:                Tue, 19 Mar 2024   Prob (F-statistic):           0.000978\n",
       "Time:                        00:50:06   Log-Likelihood:                 126.29\n",
       "No. Observations:                  46   AIC:                            -204.6\n",
       "Df Residuals:                      22   BIC:                            -160.7\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                  0.1079      0.016      6.651      0.000       0.074       0.142\n",
       "group[T.treatment]        -0.0159      0.007     -2.398      0.025      -0.030      -0.002\n",
       "C(Date)[T.Fri, Oct 24]     0.0445      0.022      1.983      0.060      -0.002       0.091\n",
       "C(Date)[T.Fri, Oct 31]    -0.0074      0.022     -0.331      0.744      -0.054       0.039\n",
       "C(Date)[T.Mon, Oct 13]    -0.0231      0.022     -1.026      0.316      -0.070       0.024\n",
       "C(Date)[T.Mon, Oct 20]    -0.0285      0.022     -1.270      0.217      -0.075       0.018\n",
       "C(Date)[T.Mon, Oct 27]     0.0328      0.022      1.458      0.159      -0.014       0.079\n",
       "C(Date)[T.Sat, Nov 1]     -0.0235      0.022     -1.047      0.306      -0.070       0.023\n",
       "C(Date)[T.Sat, Oct 11]    -0.0017      0.022     -0.074      0.941      -0.048       0.045\n",
       "C(Date)[T.Sat, Oct 18]    -0.0438      0.022     -1.950      0.064      -0.090       0.003\n",
       "C(Date)[T.Sat, Oct 25]    -0.0309      0.022     -1.375      0.183      -0.077       0.016\n",
       "C(Date)[T.Sun, Nov 2]      0.0549      0.022      2.441      0.023       0.008       0.101\n",
       "C(Date)[T.Sun, Oct 12]    -0.0347      0.022     -1.542      0.137      -0.081       0.012\n",
       "C(Date)[T.Sun, Oct 19]    -0.0178      0.022     -0.791      0.437      -0.064       0.029\n",
       "C(Date)[T.Sun, Oct 26]    -0.0222      0.022     -0.989      0.333      -0.069       0.024\n",
       "C(Date)[T.Thu, Oct 16]    -0.0228      0.022     -1.016      0.321      -0.069       0.024\n",
       "C(Date)[T.Thu, Oct 23]    -0.0046      0.022     -0.203      0.841      -0.051       0.042\n",
       "C(Date)[T.Thu, Oct 30]     0.0588      0.022      2.618      0.016       0.012       0.105\n",
       "C(Date)[T.Tue, Oct 14]    -0.0417      0.022     -1.855      0.077      -0.088       0.005\n",
       "C(Date)[T.Tue, Oct 21]    -0.0059      0.022     -0.260      0.797      -0.052       0.041\n",
       "C(Date)[T.Tue, Oct 28]    -0.0287      0.022     -1.276      0.215      -0.075       0.018\n",
       "C(Date)[T.Wed, Oct 15]    -0.0132      0.022     -0.588      0.562      -0.060       0.033\n",
       "C(Date)[T.Wed, Oct 22]    -0.0220      0.022     -0.980      0.338      -0.069       0.025\n",
       "C(Date)[T.Wed, Oct 29]     0.0466      0.022      2.076      0.050    4.77e-05       0.093\n",
       "==============================================================================\n",
       "Omnibus:                        3.871   Durbin-Watson:                   2.907\n",
       "Prob(Omnibus):                  0.144   Jarque-Bera (JB):                3.826\n",
       "Skew:                           0.000   Prob(JB):                        0.148\n",
       "Kurtosis:                       4.413   Cond. No.                         27.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit regression\n",
    "\n",
    "model1 = ols(formula=\"Enroll_Pay ~ group + C(Date)\", data=dataset_without_nas).fit()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding date to the regression model, the standard error changed -0.3599 percent.\n"
     ]
    }
   ],
   "source": [
    "std_er_dif = (model1.bse[1] - model.bse[1]) / model.bse[1]\n",
    "\n",
    "print(\n",
    "    f\"After adding date to the regression model,\\\n",
    " the standard error changed {std_er_dif:.4f} percent.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0066253765225568785"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.bse[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex4_avg_oec': 0.0941,\n",
       " 'ex5_avg_guardrail': 0.1158,\n",
       " 'ex7_ttest_pvalue': 0.8877,\n",
       " 'ex9_ttest_pvalue_clicks': 0.9264,\n",
       " 'ex10_num_obs': 46,\n",
       " 'ex11_oec_ate': 1.5888,\n",
       " 'ex11_oec_pvalue': 0.1319,\n",
       " 'ex11_guard_ate': 0.4897,\n",
       " 'ex11_guard_pvalue': 0.5928,\n",
       " 'ex14_se_treatment': 0.0066}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"ex14_se_treatment\"] = round(model1.bse[1], 4)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After adding date to the regression model (controling for date), the standard error **decreased from .010 to .007** (~ 36 percent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(results.keys()) == {\n",
    "    \"ex4_avg_oec\",\n",
    "    \"ex5_avg_guardrail\",\n",
    "    \"ex7_ttest_pvalue\",\n",
    "    \"ex9_ttest_pvalue_clicks\",\n",
    "    \"ex10_num_obs\",\n",
    "    \"ex11_guard_ate\",\n",
    "    \"ex11_guard_pvalue\",\n",
    "    \"ex11_oec_ate\",\n",
    "    \"ex11_oec_pvalue\",\n",
    "    \"ex14_se_treatment\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15\n",
    "\n",
    "Does this result have any impact on the recommendations you would offer Udacity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**By controlling for daily variance using the regression model** (adding the *Date* variable as a predictor), the **standard error of treatment effect decreased and the p-value dropped to below .05**, **indicating that controlling for daily variance, the treatment effect observed was unlikely to be due to sampling**. With this, we could conclude that **the treatment of adding a prompt making sure that the user can devote sufficient amount of time per week** ***does have an impact*** **on the metric of interest**: **it decreases the share of users clicking on the** *start free trial* **button who enrolled for free trial minus users who continued to pay after the trial**, reducing the coaching resources allocated to people who do not have the time to really engage with the materials during the trial period."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
